{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# R/Jobs Data Exploration\n",
    "\n",
    "This notebook contains my data exploration for the subreddit [r/Jobs](https://www.reddit.com/r/jobs/), a popular job search help forum on Reddit. \n",
    "\n",
    "I want to see if I can find any change in patterns after March 2020. What kind of posts trended after the start of Coronavirus pandemic lockdown in the US?\n",
    "\n",
    "### Preliminary Questions:\n",
    "\n",
    "1. What is the average number of comments (posts with a higher amount of comments have more user engagement). Median number of commnets? Median score?\n",
    "2. Are most posts (ranked top 1000 of all time) created before or after March 2020?\n",
    "3. What is the post with the highest number of comments? (most engagement)?\n",
    "4. if we subset the data frame by month, what is the top comment for each month? what is its score? which is the one with the highest amount of user engagement?\n",
    "5. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                              title  score  \\\n",
       "0           0  So real talk. Why are so may $30k to $40k per ...  12259   \n",
       "1           1  I'm an ex-recruiter for some of the top compan...   7259   \n",
       "2           2                          A Warning About Glassdoor   5697   \n",
       "3           3  America is not lacking in skilled employees, A...   4110   \n",
       "4           4  UPDATE 3: I have slipped through the cracks at...   3571   \n",
       "\n",
       "       id subreddit                                                url  \\\n",
       "0  9u3fww      jobs  https://www.reddit.com/r/jobs/comments/9u3fww/...   \n",
       "1  7y8k6p      jobs  https://www.reddit.com/r/jobs/comments/7y8k6p/...   \n",
       "2  jbod57      jobs  https://www.reddit.com/r/jobs/comments/jbod57/...   \n",
       "3  jo6lc7      jobs  https://www.reddit.com/r/jobs/comments/jo6lc7/...   \n",
       "4  3jjs1n      jobs  https://www.reddit.com/r/jobs/comments/3jjs1n/...   \n",
       "\n",
       "   num_comments                                               body  \\\n",
       "0          3975  It just seems odd that when I go on job boards...   \n",
       "1           688  **April 5, 2020 edit:** I've been getting more...   \n",
       "2           470  **EDIT**: A little info from Glassdoor that I ...   \n",
       "3           475  If every entry level job requires a year exper...   \n",
       "4          1263  Link to my original post: https://www.reddit.c...   \n",
       "\n",
       "        created         date_created  \n",
       "0  1.541368e+09  2018-11-04 16:48:13  \n",
       "1  1.518923e+09  2018-02-17 21:57:42  \n",
       "2  1.602800e+09  2020-10-15 18:16:35  \n",
       "3  1.604558e+09  2020-11-05 01:35:38  \n",
       "4  1.441350e+09  2015-09-04 03:03:16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>score</th>\n      <th>id</th>\n      <th>subreddit</th>\n      <th>url</th>\n      <th>num_comments</th>\n      <th>body</th>\n      <th>created</th>\n      <th>date_created</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>So real talk. Why are so may $30k to $40k per ...</td>\n      <td>12259</td>\n      <td>9u3fww</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/9u3fww/...</td>\n      <td>3975</td>\n      <td>It just seems odd that when I go on job boards...</td>\n      <td>1.541368e+09</td>\n      <td>2018-11-04 16:48:13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>I'm an ex-recruiter for some of the top compan...</td>\n      <td>7259</td>\n      <td>7y8k6p</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/7y8k6p/...</td>\n      <td>688</td>\n      <td>**April 5, 2020 edit:** I've been getting more...</td>\n      <td>1.518923e+09</td>\n      <td>2018-02-17 21:57:42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A Warning About Glassdoor</td>\n      <td>5697</td>\n      <td>jbod57</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/jbod57/...</td>\n      <td>470</td>\n      <td>**EDIT**: A little info from Glassdoor that I ...</td>\n      <td>1.602800e+09</td>\n      <td>2020-10-15 18:16:35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>America is not lacking in skilled employees, A...</td>\n      <td>4110</td>\n      <td>jo6lc7</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/jo6lc7/...</td>\n      <td>475</td>\n      <td>If every entry level job requires a year exper...</td>\n      <td>1.604558e+09</td>\n      <td>2020-11-05 01:35:38</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>UPDATE 3: I have slipped through the cracks at...</td>\n      <td>3571</td>\n      <td>3jjs1n</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/3jjs1n/...</td>\n      <td>1263</td>\n      <td>Link to my original post: https://www.reddit.c...</td>\n      <td>1.441350e+09</td>\n      <td>2015-09-04 03:03:16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/posts_jobs.csv')\n",
    "# that's how you do it:) (navigating up i mean)\n",
    "\n",
    "\n",
    "df.shape\n",
    "df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['index', 'title', 'score', 'id', 'subreddit', 'url', 'num_comments',\n",
       "       'body', 'created', 'date_created'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# let's rename these columns\n",
    "\n",
    "df = df.rename(columns={'Unnamed: 0':'index'})\n",
    "\n",
    "df.columns\n",
    "\n"
   ]
  },
  {
   "source": [
    "After some analysis, we find this data fram has :\n",
    "\n",
    "- 1000 observations by 9 variables (10 if you count the pandas dataframe index).\n",
    "- These variables are:\n",
    "    - Post Title\n",
    "    - Post Score in Upvotes / Downvotes\n",
    "    - Post ID \n",
    "    - Subreddit Name \n",
    "    - Direct Url Link to Post \n",
    "    - Created in seconds (Computer Time)\n",
    "    - Date Created (obtained from Computer Time)\n",
    "\n",
    "### Next Steps \n",
    "I now want to\n",
    "\n",
    "- [x] Find the median post score. \n",
    "- [x] Find the median number of comments \n",
    "- [x] Find the average number of comments \n",
    "- [x] Create month index column\n",
    "- [ ] Subset data frame by month\n",
    "- [ ] Find the most commented post from each month.\n",
    "- [ ] Find the most upvoted post from each month. Compare to most commented. \n",
    "- [ ] The highest commented AND highest upvoted post of all time\n",
    "- [ ] \n",
    "\n",
    "\n",
    "### Why do I want these Statistics?\n",
    "\n",
    "1. The median of a sample is less susepctible to outliers than the mean is, so it is better to use as something to compare scores with, but I also still want to see that mean!\n",
    "2. I wannt to see how the top post by month changed during the progression of the Coronavirus Lockdown Period. \n",
    "3. More posts implies a higher level of user engagement, even if it is a very rough measurement of engagement. I wasnt to see which posts were most engaging. \n",
    "4. However, more upvotes implies more people \"agree\" with the sentiment the poster has. \n",
    "    \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             index         score  num_comments       created\n",
       "count  1000.000000   1000.000000   1000.000000  1.000000e+03\n",
       "mean    499.500000    554.327000    132.909000  1.553596e+09\n",
       "std     288.819436    584.268464    179.286476  5.541605e+07\n",
       "min       0.000000    253.000000      1.000000  1.311579e+09\n",
       "25%     249.750000    317.500000     66.000000  1.538492e+09\n",
       "50%     499.500000    407.500000    100.000000  1.565390e+09\n",
       "75%     749.250000    615.250000    155.500000  1.594598e+09\n",
       "max     999.000000  12259.000000   3975.000000  1.608679e+09"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>created</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1.000000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>499.500000</td>\n      <td>554.327000</td>\n      <td>132.909000</td>\n      <td>1.553596e+09</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>288.819436</td>\n      <td>584.268464</td>\n      <td>179.286476</td>\n      <td>5.541605e+07</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>253.000000</td>\n      <td>1.000000</td>\n      <td>1.311579e+09</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>249.750000</td>\n      <td>317.500000</td>\n      <td>66.000000</td>\n      <td>1.538492e+09</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>499.500000</td>\n      <td>407.500000</td>\n      <td>100.000000</td>\n      <td>1.565390e+09</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>749.250000</td>\n      <td>615.250000</td>\n      <td>155.500000</td>\n      <td>1.594598e+09</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>999.000000</td>\n      <td>12259.000000</td>\n      <td>3975.000000</td>\n      <td>1.608679e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# median of entire data frame\n",
    "# there are no missing values here\n",
    "\n",
    "df.describe()\n",
    "\n",
    "\n",
    "# I see why they use millisecond time, to make it easier to parse, hahaha. \n",
    "# to get the dates i will have to get creative and make a new column for month it was posted in. maybe date_created.contains??\n",
    "\n",
    "\n",
    "# Average score: 554.327000 points. \n",
    "# Average number of comments : 132.909000\n",
    "# Average post_date (whatever that means right now): Tuesday, March 26, 2019 10:26:40 AM EST (also known as 1.553596e+09) in epoch time. interesting...... the average is after the arrival of COVID 19 to America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "407.5\n100.0\n1565390461.5\n"
     ]
    }
   ],
   "source": [
    "# get some medians now\n",
    "\n",
    "print(df['score'].median())\n",
    "print(df['num_comments'].median())\n",
    "print(df['created'].median())\n",
    "\n",
    "\n",
    "# Median Report:\n",
    "# median Score: 407.5\n",
    "# median number of comments - 100.0\n",
    "# Median date created/ posted: Friday, August 9, 2019 10:41:01.500 PM (a bit higher than the average date, does this mean top posts skew to before the pandemic?)\n",
    "# interestingly. for this subreddit, we have the media (less susceptible to outlier) posts coming from almost a year before, august 2019!!! vs the career guidance one. this could be from subreddit creation but also interesting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index                                              title  score      id  \\\n",
       "0      0  So real talk. Why are so may $30k to $40k per ...  12259  9u3fww   \n",
       "1      1  I'm an ex-recruiter for some of the top compan...   7259  7y8k6p   \n",
       "2      2                          A Warning About Glassdoor   5697  jbod57   \n",
       "3      3  America is not lacking in skilled employees, A...   4110  jo6lc7   \n",
       "4      4  UPDATE 3: I have slipped through the cracks at...   3571  3jjs1n   \n",
       "\n",
       "  subreddit                                                url  num_comments  \\\n",
       "0      jobs  https://www.reddit.com/r/jobs/comments/9u3fww/...          3975   \n",
       "1      jobs  https://www.reddit.com/r/jobs/comments/7y8k6p/...           688   \n",
       "2      jobs  https://www.reddit.com/r/jobs/comments/jbod57/...           470   \n",
       "3      jobs  https://www.reddit.com/r/jobs/comments/jo6lc7/...           475   \n",
       "4      jobs  https://www.reddit.com/r/jobs/comments/3jjs1n/...          1263   \n",
       "\n",
       "                                                body       created  \\\n",
       "0  It just seems odd that when I go on job boards...  1.541368e+09   \n",
       "1  **April 5, 2020 edit:** I've been getting more...  1.518923e+09   \n",
       "2  **EDIT**: A little info from Glassdoor that I ...  1.602800e+09   \n",
       "3  If every entry level job requires a year exper...  1.604558e+09   \n",
       "4  Link to my original post: https://www.reddit.c...  1.441350e+09   \n",
       "\n",
       "          date_created                month  \n",
       "0  2018-11-04 16:48:13  2018-11-04 16:48:13  \n",
       "1  2018-02-17 21:57:42  2018-02-17 21:57:42  \n",
       "2  2020-10-15 18:16:35              October  \n",
       "3  2020-11-05 01:35:38             November  \n",
       "4  2015-09-04 03:03:16  2015-09-04 03:03:16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>title</th>\n      <th>score</th>\n      <th>id</th>\n      <th>subreddit</th>\n      <th>url</th>\n      <th>num_comments</th>\n      <th>body</th>\n      <th>created</th>\n      <th>date_created</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>So real talk. Why are so may $30k to $40k per ...</td>\n      <td>12259</td>\n      <td>9u3fww</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/9u3fww/...</td>\n      <td>3975</td>\n      <td>It just seems odd that when I go on job boards...</td>\n      <td>1.541368e+09</td>\n      <td>2018-11-04 16:48:13</td>\n      <td>2018-11-04 16:48:13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>I'm an ex-recruiter for some of the top compan...</td>\n      <td>7259</td>\n      <td>7y8k6p</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/7y8k6p/...</td>\n      <td>688</td>\n      <td>**April 5, 2020 edit:** I've been getting more...</td>\n      <td>1.518923e+09</td>\n      <td>2018-02-17 21:57:42</td>\n      <td>2018-02-17 21:57:42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A Warning About Glassdoor</td>\n      <td>5697</td>\n      <td>jbod57</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/jbod57/...</td>\n      <td>470</td>\n      <td>**EDIT**: A little info from Glassdoor that I ...</td>\n      <td>1.602800e+09</td>\n      <td>2020-10-15 18:16:35</td>\n      <td>October</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>America is not lacking in skilled employees, A...</td>\n      <td>4110</td>\n      <td>jo6lc7</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/jo6lc7/...</td>\n      <td>475</td>\n      <td>If every entry level job requires a year exper...</td>\n      <td>1.604558e+09</td>\n      <td>2020-11-05 01:35:38</td>\n      <td>November</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>UPDATE 3: I have slipped through the cracks at...</td>\n      <td>3571</td>\n      <td>3jjs1n</td>\n      <td>jobs</td>\n      <td>https://www.reddit.com/r/jobs/comments/3jjs1n/...</td>\n      <td>1263</td>\n      <td>Link to my original post: https://www.reddit.c...</td>\n      <td>1.441350e+09</td>\n      <td>2015-09-04 03:03:16</td>\n      <td>2015-09-04 03:03:16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Now we subset by month by creating a new column called....\"month\", haha. \n",
    "\n",
    "df['month'] = df['date_created'] # initialize\n",
    "\n",
    "df.columns[0]\n",
    "df.columns[0] # this only returns a string haha\n",
    "\n",
    "type(df['date_created'][2])\n",
    "iter = 0\n",
    "\n",
    "for x in df['date_created']:\n",
    "    #print(iter)\n",
    "    #print(df['date_created'][iter])\n",
    "\n",
    "    # actual logic here\n",
    "    if '2020-02' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'February'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-03' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'March'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-04' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'April'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-05' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'May'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-06' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'June'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-07' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'July'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-08' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'August'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-09' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'September'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-10' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'October'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-11' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'November'\n",
    "        #print(df['month'][iter])\n",
    "    if '2020-12' in x:\n",
    "        #print(df['month'][iter]) #check\n",
    "        df['month'][iter] = 'December'\n",
    "        #print(df['month'][iter])\n",
    "    iter+=1\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " # was testing out logic here\n",
    " #print('2020-05' in df['date_created'][2])\n",
    "\n",
    " #print(df['date_created'][2])"
   ]
  },
  {
   "source": [
    "# Febraury 2020 (Control Month) Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            index        score  num_comments       created\ncount   24.000000    24.000000     24.000000  2.400000e+01\nmean   537.291667   457.041667    104.125000  1.582017e+09\nstd    247.859266   217.999098     62.154305  6.872226e+05\nmin     49.000000   267.000000      1.000000  1.580554e+09\n25%    352.500000   323.500000     73.750000  1.581525e+09\n50%    601.000000   368.500000     91.500000  1.582031e+09\n75%    736.250000   500.000000    135.250000  1.582633e+09\nmax    927.000000  1186.000000    233.000000  1.582951e+09\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'job_feb.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-bad435d2c337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mfeb_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mfeb_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job_feb.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'job_feb.csv'"
     ]
    }
   ],
   "source": [
    "is_feb = df['month']=='February'\n",
    "\n",
    "feb_df = df[is_feb]\n",
    "feb_df.head()\n",
    "\n",
    "#print(march_df.shape)\n",
    "\n",
    "# top comment from march now\n",
    "\n",
    "print(feb_df.describe())\n",
    "\n",
    "\n",
    "# get some medians now\n",
    "\n",
    "# median score for march\n",
    "#print(march_df['score'].median())\n",
    "\n",
    "#  median number of comments for march\n",
    "#print(march_df['num_comments'].median())\n",
    "\n",
    "\n",
    "\n",
    "feb_df[feb_df['score']==feb_df['score'].max()]['date_created'] \n",
    "feb_df[feb_df['score']==feb_df['score'].max()].head()\n",
    "\n",
    "feb_df.head()\n",
    "\n",
    "feb_df.to_csv('job_feb.csv')\n"
   ]
  },
  {
   "source": [
    "## March Analysis for r/Jobs\n",
    "\n",
    "| Statistic   | March Posts | --Top 1000 Form Posts of All Time--\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Number of Posts  | 17       | 1000 |\n",
    "| Average Post Score | 431.058824 | 554.327000 | \n",
    "| Average Number of Comments|  111.352941* | 132.909000|\n",
    "| Highest Number of Comments on Post | 272.000000  | 3975.000000\t|\n",
    "| Highest Post Score | 1262.000000  | 12259.000000 |\n",
    "\n",
    "\n",
    "In comparison to the top 1000 posts of all time on CareerGuidance, March had a higher average number of comments. To me, this implies a higher level of user engagement. \n",
    "\n",
    "#### Most interesting post from March Posts: \n",
    "[highest num comments](https://www.reddit.com/r/jobs/comments/fibuqr/what_do_people_do_in_office_jobs/)\n",
    "\n",
    "[highest score](https://www.reddit.com/r/jobs/comments/fkmlot/there_should_be_some_kind_of_regulation_where_job/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_march = df['month']=='March'\n",
    "\n",
    "march_df = df[is_march]\n",
    "march_df.head()\n",
    "\n",
    "#print(march_df.shape)\n",
    "\n",
    "# top comment from march now\n",
    "\n",
    "#print(march_df.describe())\n",
    "\n",
    "\n",
    "# get some medians now\n",
    "\n",
    "# median score for march\n",
    "#print(march_df['score'].median())\n",
    "\n",
    "#  median number of comments for march\n",
    "#print(march_df['num_comments'].median())\n",
    "#march_df[march_df['num_comments']==march_df['num_comments'].max()].head()\n",
    "\n",
    "#march_df[march_df['num_comments']==march_df['score'].max()]['date_created']     \n",
    "\n",
    "march_df[march_df['score']==march_df['score'].max()]['date_created'] \n",
    "march_df[march_df['score']==march_df['score'].max()].head()\n",
    "\n",
    "march_df.to_csv('job_march.csv')\n"
   ]
  },
  {
   "source": [
    "## April Analysis for r/Jobs\n",
    "\n",
    "| Statistic   | March Posts | --Top 1000 Form Posts of All Time--\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Number of Posts  | 0       | 0 |\n",
    "| Average Post Score | 0.0 | 0.0 | \n",
    "| Average Number of Comments|0 | 0\n",
    "| Highest Number of Comments on Post | 0  | 0 |\n",
    "| Highest Post Score | 0 | 0 |\n",
    "\n",
    "### interesting post from April:\n",
    "\n",
    "[highest num of comments](https://www.reddit.com/r/jobs/comments/g8b9fr/what_are_some_niche_jobs_that_while_not_that/)\n",
    "\n",
    "[highest score](https://www.reddit.com/r/jobs/comments/g6wil1/why_do_nearly_all_entrylevel_jobs_require/)\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "is_april = df['month']=='April'\n",
    "\n",
    "april_df = df[is_april]\n",
    "april_df.head()\n",
    "\n",
    "print(april_df.shape)\n",
    "\n",
    "# top comment from march now\n",
    "\n",
    "print(april_df.describe())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "april_df[april_df['num_comments']==april_df['score'].max()]['date_created'] \n",
    "\n",
    "\n",
    "april_df[april_df['score']==april_df['score'].max()]['date_created'] \n",
    "april_df[april_df['score']==april_df['score'].max()].head()\n",
    "\n",
    "\n",
    "april_df[april_df['num_comments']==april_df['num_comments'].max()].head()\n",
    "\n",
    "april_df.to_csv('job_april.csv')\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20, 11)\n            index       score  num_comments       created\ncount   20.000000   20.000000     20.000000  2.000000e+01\nmean   681.900000  359.050000    124.650000  1.587089e+09\nstd    222.775294  109.097482     63.578609  7.341073e+05\nmin    174.000000  256.000000     26.000000  1.585888e+09\n25%    545.500000  286.250000     82.750000  1.586606e+09\n50%    683.500000  343.000000    112.500000  1.587080e+09\n75%    865.750000  393.000000    148.250000  1.587727e+09\nmax    987.000000  728.000000    301.000000  1.588225e+09\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# May Analysis\n",
    "\n",
    "1. [top comments]()\n",
    "2. [top score](https://www.reddit.com/r/jobs/comments/ggagbp/does_anyone_else_find_linkedin_toxic/)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "is_may = df['month']=='May'\n",
    "\n",
    "may_df = df[is_may]\n",
    "may_df.head()\n",
    "\n",
    "print(may_df.shape)\n",
    "\n",
    "# top comment from march now\n",
    "\n",
    "print(may_df.describe())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "may_df[may_df['num_comments']==may_df['score'].max()]['date_created'] \n",
    "\n",
    "\n",
    "may_df[may_df['score']==may_df['score'].max()]['date_created'] \n",
    "may_df[may_df['score']==may_df['score'].max()].head()\n",
    "\n",
    "\n",
    "#may_df[may_df['num_comments']==may_df['num_comments'].max()].head()\n",
    "\n",
    "may_df.to_csv('jobs_may.csv')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_july = df['month']=='June'\n",
    "\n",
    "june_df = df[is_june]\n",
    "may_df.head()\n",
    "\n",
    "print(may_df.shape)\n",
    "\n",
    "# top comment from march now\n",
    "\n",
    "print(may_df.describe())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "may_df[may_df['num_comments']==may_df['score'].max()]['date_created'] \n",
    "\n",
    "\n",
    "may_df[may_df['score']==may_df['score'].max()]['date_created'] \n",
    "may_df[may_df['score']==may_df['score'].max()].head()\n",
    "\n",
    "\n",
    "#may_df[may_df['num_comments']==may_df['num_comments'].max()].head()"
   ]
  },
  {
   "source": [
    "### What are the top 5 most upvoted post of all time, after the start of the Pandemic in the US?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df[df['month'] in {'March' | 'April' | 'May' |'June' |'July'|'August'| 'Septermber'|'October'| 'November'|'Deember'}]\n",
    "\n",
    "is_covid = (df['month']!='March')or (df['month']=='March')or(df['month']=='April')or(df['month']=='May')or(df['month']=='June')or(df['month']=='July')or(df['month']=='August')or(df['month']=='September')or(df['month']=='October')or(df['month']=='December')\n",
    "\n",
    "covid_df=df[is_covid]\n",
    "\n",
    "\n",
    "\n",
    "covid_df[covid_df['score']==covid_df['score'].max()]['date_created'] \n",
    "covid_df[covid_df['score']==covid_df['score'].max()].head()\n",
    "\n",
    "\n",
    "covid_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['month'] in {'March' | 'April' | 'May' |'June' |'July'|'August'| 'Septermber'|'October'| 'November'|'Deember'}]\n",
    "\n",
    "is_not_covid = df['date_created'] < '2020-03-01'\n",
    "\n",
    "not_covid_df=df[is_not_covid]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "not_covid_df[not_covid_df['score']==not_covid_df['score'].max()]['date_created'] \n",
    "not_covid_df[not_covid_df['score']==not_covid_df['score'].max()].head()\n",
    "\n",
    "\n",
    "not_covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'2020-08'> '2020-07'\n",
    "\n",
    "# trying out date truth values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code for plot\n",
    "\n",
    "labels = ['Top Post', '2nd Top Post', '3rd Top Post','','']\n",
    "men_means = [20, 34, 30, 35, 27]\n",
    "women_means = [25, 32, 34, 20, 25]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='Men')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "#fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# What share of the top 1000 posts does 2020 take in r/jobs?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count representation by year\n",
    "ct_2020 = 0\n",
    "ct_2019 = 0\n",
    "ct_2018 = 0\n",
    "ct_2017 = 0\n",
    "ct_2016 = 0\n",
    "\n",
    "for x in df['date_created']:\n",
    "    if '2020' in x:\n",
    "        ct_2020 += 1\n",
    "    if '2019' in x:\n",
    "        ct_2019 += 1\n",
    "    if '2018' in x:\n",
    "        ct_2018 += 1\n",
    "    if '2017' in x:\n",
    "        ct_2017 += 1\n",
    "    if '2016' in x:\n",
    "        ct_2016 += 1\n",
    "\n",
    "print(ct_2020, ct_2019, ct_2018, ct_2017, ct_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['2020', '2019', '2018','2017','2016']\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Example data\n",
    "years = ('2020', '2019', '2018','2017','2016')\n",
    "y_pos = np.arange(len(years))\n",
    "num_posts = [393 ,308,157,41,35]\n",
    "\n",
    "ax.barh(y_pos, num_posts, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(years)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Number of Posts in Top 1000 Posts of All Time')\n",
    "ax.set_title('Posts in Top 1000 (R/Jobs)')\n",
    "\n",
    "plt.show()"
   ]
  }
 ]
}